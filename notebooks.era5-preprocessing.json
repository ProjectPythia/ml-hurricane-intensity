{"version":2,"kind":"Notebook","sha256":"243dd9e2932cdfe4e59caff0567965ce6e1a5b8a5cb20ea86a65adb63b394976","slug":"notebooks.era5-preprocessing","location":"/notebooks/era5_preprocessing.ipynb","dependencies":[],"frontmatter":{"title":"ERA5 Data Preprocessing","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"Nirmal Alex, Matthew Lynne","given":"Matthew Lynne","family":"Nirmal Alex"},"name":"Nirmal Alex, Matthew Lynne","id":"contributors-myst-generated-uid-0"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"github":"https://github.com/ProjectPythia/ml-hurricane-intensity","copyright":"2024","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"numbering":{"title":{"offset":1}},"edit_url":"https://github.com/ProjectPythia/ml-hurricane-intensity/blob/main/notebooks/era5_preprocessing.ipynb","exports":[{"format":"ipynb","filename":"era5_preprocessing.ipynb","url":"/ml-hurricane-intensity/build/era5_preprocessing-c1949c597f96b1e0add5109eb0fec148.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"thematicBreak","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hAnUAL8sWk"}],"key":"fYNnynDg1n"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Overview","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DrylT9KlBI"}],"identifier":"overview","label":"Overview","html_id":"overview","implicit":true,"key":"evrgxPniuY"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Here, we will use the processed IBTRACKS data to select ERA5 environmental variables associated with each cyclone.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"wxDvb8UPK3"}],"key":"vSSmE1LVbP"}],"key":"karnRZ3eKR"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Prerequisites","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Lx676MS2v3"}],"identifier":"prerequisites","label":"Prerequisites","html_id":"prerequisites","implicit":true,"key":"tcUA7EVpco"},{"type":"table","position":{"start":{"line":2,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"tableRow","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"tableCell","header":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Concepts","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"fZX19QlQEZ"}],"key":"SUuCpXyuqE"},{"type":"tableCell","header":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Importance","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"WVk9rcFelq"}],"key":"xgvfHLMOrK"},{"type":"tableCell","header":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Notes","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"LPdOZ3uYrD"}],"key":"MBZFDvvjPO"}],"key":"fsL5vgWrWX"},{"type":"tableRow","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"link","url":"https://foundations.projectpythia.org/core/numpy/","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Intro to NUMPY","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"hkOzS9n8gD"}],"urlSource":"https://foundations.projectpythia.org/core/numpy/","key":"Pko7vGyPLH"}],"key":"CdMAmjjL4S"},{"type":"tableCell","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Necessary","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"RceGOZJNpg"}],"key":"TGE4iooZZp"},{"type":"tableCell","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[],"key":"dtCKE1Nlkm"}],"key":"sFazcn9XtH"},{"type":"tableRow","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"link","url":"https://foundations.projectpythia.org/core/numpy/","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Intro to PANDAS","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"X56PR0dUAD"}],"urlSource":"https://foundations.projectpythia.org/core/numpy/","key":"jjFEiQtE1K"}],"key":"ROBI9FTyKa"},{"type":"tableCell","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Necessary","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"kLw9fAM0WW"}],"key":"XhGd7EdWrP"},{"type":"tableCell","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[],"key":"nlnsoz5swR"}],"key":"daeEXw8bty"},{"type":"tableRow","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"link","url":"https://foundations.projectpythia.org/core/xarray/","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Intro to XARRAY","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"WmQbQFJTaQ"}],"urlSource":"https://foundations.projectpythia.org/core/xarray/","key":"GzmZIPplLj"}],"key":"LE0nrz6kjN"},{"type":"tableCell","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Necessary","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"OMDvBFCWVg"}],"key":"ELuIh2FyzQ"},{"type":"tableCell","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[],"key":"gGtBsWYGjy"}],"key":"RzqsVEXW12"},{"type":"tableRow","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Project management","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"aKXWXsxAEZ"}],"key":"Nu1ne85e7V"},{"type":"tableCell","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Helpful","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"WAq6nLbBIb"}],"key":"h0SXtIDFrT"},{"type":"tableCell","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[],"key":"a2goFaH1wA"}],"key":"xujfn7sPjt"}],"key":"VpYU6Wnz5c"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Time to learn","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"aI2bG9Am2e"}],"key":"SSdpM7aPOF"},{"type":"text","value":": ~15 minntes","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"cCZ7socR6B"}],"key":"t5y7LrfsdZ"}],"key":"g8jTN9I3ka"}],"key":"aPFSDyHkm2"},{"type":"block","kind":"notebook-content","children":[{"type":"thematicBreak","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kMDSW6MiVe"}],"key":"FbMVXN367D"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Imports","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"N4mRdC0hNs"}],"identifier":"imports","label":"Imports","html_id":"imports","implicit":true,"key":"Droqh5nvO9"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Begin your body of content with another ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"EiEmKmpblP"},{"type":"inlineCode","value":"---","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"mp8dMjbTxr"},{"type":"text","value":" divider before continuing into this section, then remove this body text and populate the following code cell with all necessary Python imports ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"cfe6SdTshN"},{"type":"strong","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"up-front","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"pnbfPhHLK9"}],"key":"AnwIyH6hI8"},{"type":"text","value":":","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"GitkhLbh4q"}],"key":"ZGYX50NNGr"}],"key":"thpVWviPSJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import xarray as xr \nfrom dask.distributed import Client\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport pandas as pd\nimport glob\nfrom global_land_mask import globe\nimport cartopy.feature as cfeature\nfrom matplotlib.path import Path\nimport matplotlib.patches as patches\nfrom matplotlib import patheffects\nimport numpy as np\nimport dask","key":"tDrLY0jBRZ"},{"type":"output","id":"1DH-hCjU3vYxZSfCaXp2G","data":[],"key":"nwm8NS3mLI"}],"key":"invQa5Sfzq"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Edit and pad ERA5 data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"omhUW1ZhlZ"}],"identifier":"edit-and-pad-era5-data","label":"Edit and pad ERA5 data","html_id":"edit-and-pad-era5-data","implicit":true,"key":"KKNTLp2HOr"}],"key":"nZprY3X85O"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In this section, we will select ERA5 data within a 5x5 latitude/longitude grid centered at each cyclone center at each time step in our dataset. We will then have to pad the data to account for instances in which grid cells occur over land.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ODLjmYRXtC"}],"key":"HaCVuHxllF"}],"key":"wUiA4DI2VH"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"input_dsets = xr.open_dataset('~/Data/final_proc_5yr_6h.nc')","key":"E9RAtFmHOg"},{"type":"output","id":"DmpGNDx-HAZReJtvqXK-A","data":[{"output_type":"error","traceback":"\u001b[31m---------------------------------------------------------------------------\u001b[39m\n\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.12/site-packages/xarray/backends/file_manager.py:211\u001b[39m, in \u001b[36mCachingFileManager._acquire_with_cache_info\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.12/site-packages/xarray/backends/lru_cache.py:56\u001b[39m, in \u001b[36mLRUCache.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m._cache.move_to_end(key)\n\n\u001b[31mKeyError\u001b[39m: [<class 'netCDF4._netCDF4.Dataset'>, ('/home/runner/Data/final_proc_5yr_6h.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '19419ca6-aab0-4e9c-85a6-6771f0d88d62']\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)\n\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m input_dsets = \u001b[43mxr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m~/Data/final_proc_5yr_6h.nc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.12/site-packages/xarray/backends/api.py:715\u001b[39m, in \u001b[36mopen_dataset\u001b[39m\u001b[34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, create_default_indexes, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[39m\n\u001b[32m    703\u001b[39m decoders = _resolve_decoders_kwargs(\n\u001b[32m    704\u001b[39m     decode_cf,\n\u001b[32m    705\u001b[39m     open_backend_dataset_parameters=backend.open_dataset_parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    711\u001b[39m     decode_coords=decode_coords,\n\u001b[32m    712\u001b[39m )\n\u001b[32m    714\u001b[39m overwrite_encoded_chunks = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33moverwrite_encoded_chunks\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m backend_ds = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m ds = _dataset_from_backend_dataset(\n\u001b[32m    722\u001b[39m     backend_ds,\n\u001b[32m    723\u001b[39m     filename_or_obj,\n\u001b[32m   (...)\u001b[39m\u001b[32m    734\u001b[39m     **kwargs,\n\u001b[32m    735\u001b[39m )\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:671\u001b[39m, in \u001b[36mNetCDF4BackendEntrypoint.open_dataset\u001b[39m\u001b[34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, auto_complex, lock, autoclose)\u001b[39m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_dataset\u001b[39m(\n\u001b[32m    650\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    651\u001b[39m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m | os.PathLike[Any] | ReadBuffer | AbstractDataStore,\n\u001b[32m   (...)\u001b[39m\u001b[32m    668\u001b[39m     autoclose=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    669\u001b[39m ) -> Dataset:\n\u001b[32m    670\u001b[39m     filename_or_obj = _normalize_path(filename_or_obj)\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m     store = \u001b[43mNetCDF4DataStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    684\u001b[39m     store_entrypoint = StoreBackendEntrypoint()\n\u001b[32m    685\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:457\u001b[39m, in \u001b[36mNetCDF4DataStore.open\u001b[39m\u001b[34m(cls, filename, mode, format, group, clobber, diskless, persist, auto_complex, lock, lock_maker, autoclose)\u001b[39m\n\u001b[32m    453\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mauto_complex\u001b[39m\u001b[33m\"\u001b[39m] = auto_complex\n\u001b[32m    454\u001b[39m manager = CachingFileManager(\n\u001b[32m    455\u001b[39m     netCDF4.Dataset, filename, mode=mode, kwargs=kwargs\n\u001b[32m    456\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:398\u001b[39m, in \u001b[36mNetCDF4DataStore.__init__\u001b[39m\u001b[34m(self, manager, group, mode, lock, autoclose)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;28mself\u001b[39m._group = group\n\u001b[32m    397\u001b[39m \u001b[38;5;28mself\u001b[39m._mode = mode\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m \u001b[38;5;28mself\u001b[39m.format = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mds\u001b[49m.data_model\n\u001b[32m    399\u001b[39m \u001b[38;5;28mself\u001b[39m._filename = \u001b[38;5;28mself\u001b[39m.ds.filepath()\n\u001b[32m    400\u001b[39m \u001b[38;5;28mself\u001b[39m.is_remote = is_remote_uri(\u001b[38;5;28mself\u001b[39m._filename)\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:466\u001b[39m, in \u001b[36mNetCDF4DataStore.ds\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:460\u001b[39m, in \u001b[36mNetCDF4DataStore._acquire\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nc4_require_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.12/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.12/site-packages/xarray/backends/file_manager.py:199\u001b[39m, in \u001b[36mCachingFileManager.acquire_context\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    198\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     file, cached = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    201\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m file\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.12/site-packages/xarray/backends/file_manager.py:217\u001b[39m, in \u001b[36mCachingFileManager._acquire_with_cache_info\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    215\u001b[39m     kwargs = kwargs.copy()\n\u001b[32m    216\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._mode\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode == \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28mself\u001b[39m._mode = \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m\n\n\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2521\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Dataset.__init__\u001b[39m\u001b[34m()\u001b[39m\n\n\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2158\u001b[39m, in \u001b[36mnetCDF4._netCDF4._ensure_nc_success\u001b[39m\u001b[34m()\u001b[39m\n\n\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/runner/Data/final_proc_5yr_6h.nc'","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/home/runner/Data/final_proc_5yr_6h.nc'"}],"key":"UYh4egcTbs"}],"key":"avoHYFCFCb"},{"type":"block","kind":"notebook-content","children":[{"type":"admonition","kind":"hint","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Hint","key":"zNLTx1GvrH"}],"key":"XVcWgJbGZm"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The coriolis parameter is a function of latitude only. However, cyclones tend to move in preferred directions based on latitude and in turn the magnitude of this parameter. This is why the coriolis parameter is chosen to be one of the predictor variables of our AI model. This variable is calculated below.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"jUs79O90Vb"}],"key":"d7kUtWPMOk"}],"key":"XPyVgeDDXz"}],"key":"ShGtuDhK1L"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# calculating coriolis parameter \ncor_parms =  2 * 7.29 * 1e-5 * np.sin(np.radians(input_dsets['latitude']))\n\ninput_dsets['cor_params'] = xr.DataArray(cor_parms,\n                                            name='cor_params'\n                                            ).broadcast_like(input_dsets['r'])","key":"XrmkVRCD52"},{"type":"output","id":"AcDjPAigAjvtByOn6eG8Y","data":[],"key":"lBrply0974"}],"key":"gaPplVcRTT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ib_data_processed_6h = pd.read_csv('../test_folder/ib_data_processed_6h.csv')","key":"ygi7uJDt2k"},{"type":"output","id":"_FumoXh-bG8BJ7NOFXAHQ","data":[],"key":"mniSdP8JdO"}],"key":"JzjDX0r3sj"},{"type":"block","kind":"notebook-content","children":[{"type":"admonition","kind":"hint","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Hint","key":"yq0E1U2pBD"}],"key":"FUcygunv5E"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"When training our AI model, we want all cyclones to have the same number of time steps. Realistically this does not happen in the real world. Therefore, we must pad each cyclone track with “dummy” values until the lifespan of the cyclone is the same as that of the longest lasting cyclone in our dataset.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"XbpARXhaMQ"}],"key":"p8BSGXrf1S"}],"key":"mBOh7IY9kJ"}],"key":"CZwk0c3c4a"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"final_data = []\nmax_len = ib_data_processed_6h.groupby('id').size().max()  # assuming max length is 3 hours per storm","key":"mNyZpp7DuW"},{"type":"output","id":"zrYF0DKYkw9j5a_UKr_dV","data":[],"key":"ojAvsI2tdS"}],"key":"NOQvhD5RWI"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Edit predictors for each cyclone","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pdPlTFweA4"}],"identifier":"edit-predictors-for-each-cyclone","label":"Edit predictors for each cyclone","html_id":"edit-predictors-for-each-cyclone","implicit":true,"key":"SAwrcGRifM"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Here we can move on to our second objective, to explicitly edit the predictors that will be used by the machine learning model. We wish to center each cyclone within a 5x5 grid at each time step. We will then select the data at each grid cell for each variable of interest including sea surface temperatures, 500 hPa relatice humidity, pressure, vertical wind shear, 850 hPa relative vorticity, and the coriolis parameter.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Sezt3gcJrp"}],"key":"T2Pbl90vzl"}],"key":"wMIFPa5THg"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"for id_number,group in ib_data_processed_6h.groupby('id'):\n    events_data = []\n    for index,row in group.iterrows():\n        lat = int(row['LAT'])\n        lon = int(row['LON'])\n        time = row['datetime']\n        \n        #We want data in a 5x5 latitude/longitude grid centered on the cyclone latitude/longitude\n        latmin = lat - 2\n        latmax = lat + 2\n        lonmin = lon - 2\n        lonmax = lon + 2\n        sel_data = input_dsets.sel(latitude=slice(latmax, latmin), longitude=slice(lonmin, lonmax), time=time)\n        \n            \n        final_xr = sel_data.rename({'latitude': 'y', 'longitude': 'x'})\n        final_xr['x'] = np.arange(0,final_xr.sizes['x'])\n        final_xr['y'] = np.arange(0,final_xr.sizes['y'])\n        \n        # fill NaN values with zeros along the x and y dimensions\n        for jj in final_xr.data_vars:\n            final_xr[jj].fillna(0)  # Fill NaN values\n        \n        #Recall that we are trying to predict the wind speed.\n        #Hence, our target is USA_WIND\n        final_xr['target'] = row['USA_WIND']    \n        events_data.append(final_xr)\n    \n    final_event = xr.concat(events_data,dim='time')\n    \n    #Pad data with zeros up to the maximum time\n    if len(final_event.time) <= max_len:\n        new_time = pd.date_range(start=final_event['time'].min().values, periods=max_len ,freq='6h')\n        padded_data = final_event.reindex(time=new_time, fill_value=0.0)\n    else:\n        padded_data = final_event\n    \n    lead_time = np.arange(0,max_len*6 ,6)\n    padded_data['lead'] = ('time', lead_time)\n    padded_data = padded_data.assign_coords({'lead': padded_data['lead'].astype(int)})\n    \n    # swap time and lead dimensions\n    padded_data = padded_data.swap_dims({'time': 'lead'})\n    padded_data['id'] = id_number \n    padded_data = padded_data.set_coords('id')\n    \n    # convert the time dimension to a variable\n    final_data.append(padded_data)","key":"xVAQZQt0F5"},{"type":"output","id":"_2kmdS9NVzqVAUsvp_Wks","data":[],"key":"V0ldlqsu93"}],"key":"KxRoiPFK05"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"final_input_padded = xr.concat(final_data, dim='id')\nfinal_input_padded","key":"yqr49DMokb"},{"type":"output","id":"0iwQfXA70tXa1hhp4sV5S","data":[],"key":"BE8zD4Lfwv"}],"key":"VvUHMqvs6U"},{"type":"block","kind":"notebook-content","children":[{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"UCxkXFHvpy"}],"key":"NSx8yb1UgJ"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Recall that our “target” variable, or the variable we want to predict is the wind speed. We take the wind speed from ERA5 to initially train our model.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"dej5v3We6Y"}],"key":"cbPssTXpL2"}],"key":"XKeODxOMpo"}],"key":"QlocFhtPtc"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"final_input_padded.to_netcdf('~/ml-hurricane-intensity/test_folder/input_predictands.nc')","key":"RbWwGmLGdq"},{"type":"output","id":"j7A6BYTvaI0fPDUAN-uZp","data":[],"key":"FL7fdW5mBf"}],"key":"D9JuuZemBJ"},{"type":"block","kind":"notebook-content","children":[{"type":"thematicBreak","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VfvyOtmnYa"}],"key":"cGnTUfY0Xq"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Summary","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dormXW8ij2"}],"identifier":"summary","label":"Summary","html_id":"summary","implicit":true,"key":"USMVimprYt"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Here, we selected and edited ERA5 data associated with the cyclones at each time step in our dataset. This involved gathering data for each variable of interest within a 5x5 grid. We also needed to be sure to mask out all grid cells corresponding to land as our AI model will only take into account grid cells over water.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"QGKWRbojV4"}],"key":"F0K1ADvAz7"},{"type":"heading","depth":3,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"What’s next?","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"kXqtLodPyX"}],"identifier":"whats-next","label":"What’s next?","html_id":"whats-next","implicit":true,"key":"OC1KNkVjyp"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"We have now officially preprocessed all of our data! Next, we will test each variable of interest to get a sense of how well it can act as a predictor for cyclone intensity. After this, we will begin setting up our AI model!","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"CSQAzr61aE"}],"key":"B7iSUNY8cA"}],"key":"eMhvx4BuIm"}],"key":"d4l0VDt00w"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Preprocess IBTRACK data","url":"/notebooks/ibtrack-preprocessing","group":"Data Preprocessing"}}},"domain":"http://localhost:3000"}